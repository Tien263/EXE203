from typing import List, Dict, Optional
import os
import json
import re


class LLMService:
    def __init__(self):
        """Kh·ªüi t·∫°o LLM service v·ªõi debug chi ti·∫øt"""
        self.client = None
        self.gemini_model = None
        self.model_type = "none"
        self.init_error = None
        
        print(f"[DEBUG] Initializing LLM Service...")
        print(f"[DEBUG] VERSION: 2026-01-25 Auto-Detect Functionality")
        
        # Check environment variables
        openai_key = os.getenv("OPENAI_API_KEY", "")
        gemini_key = os.getenv("GEMINI_API_KEY", "")
        
        print(f"[DEBUG] OPENAI_API_KEY: {'Found' if openai_key else 'Not found'}")
        print(f"[DEBUG] GEMINI_API_KEY: {'Found' if gemini_key else 'Not found'}")
        
        # Try OpenAI first
        if openai_key:
            try:
                print("[DEBUG] Attempting to import OpenAI...")
                from openai import OpenAI
                print("[DEBUG] OpenAI imported successfully")
                
                print("[DEBUG] Creating OpenAI client...")
                self.client = OpenAI(api_key=openai_key)
                self.model_type = "openai"
                print("[OK] ‚úÖ S·ª≠ d·ª•ng OpenAI ChatGPT - Ch·∫•t l∆∞·ª£ng cao nh·∫•t!")
                return
                
            except ImportError as e:
                self.init_error = f"OpenAI Import Error: {str(e)}"
                print(f"[ERROR] OpenAI import failed: {e}")
            except Exception as e:
                self.init_error = f"OpenAI Init Error: {str(e)}"
                print(f"[ERROR] OpenAI initialization failed: {e}")
        else:
            print("[DEBUG] No OpenAI API key found")
        
        if gemini_key:
            try:
                print("[DEBUG] Attempting to use Gemini...")
                import google.generativeai as genai
                genai.configure(api_key=gemini_key)
                
                # List of models to try in order of preference
                candidate_models = [
                    'gemini-1.5-flash',
                    'gemini-1.5-flash-latest',
                    'gemini-1.5-pro',
                    'gemini-1.5-pro-latest',
                    'gemini-1.0-pro',
                    'gemini-pro'
                ]
                
                selected_model = None
                error_logs = []
                available_models_log = "Could not list models"
                
                # Try to list models to confirm availability (optional but good for debugging)
                try:
                    available_models = [m.name for m in genai.list_models()]
                    available_models_log = ", ".join(available_models)
                    print(f"[DEBUG] Available Gemini models: {available_models}")
                except Exception as ex:
                    print(f"[ERROR] Failed to list models: {ex}")
                    error_logs.append(f"ListModels Error: {str(ex)}")

                # Try initializing each model
                for model_name in candidate_models:
                    try:
                        print(f"[DEBUG] Trying model: {model_name}")
                        model = genai.GenerativeModel(model_name)
                        
                        # Test the model with a simple prompt to ensure it works
                        response = model.generate_content("test")
                        if response:
                            selected_model = model_name
                            self.gemini_model = model
                            self.model_type = "gemini"
                            print(f"[OK] ‚úÖ S·ª≠ d·ª•ng th√†nh c√¥ng Google Gemini Model: {model_name}")
                            return
                    except Exception as e:
                        error_msg = str(e)
                        # Simplify error message to save space
                        if "404" in error_msg: error_msg = "404 Not Found"
                        elif "403" in error_msg: error_msg = "403 Permission Denied"
                        
                        error_logs.append(f"{model_name}: {error_msg}")
                        print(f"[DEBUG] Model {model_name} failed: {e}")
                        continue
                
                if not selected_model:
                     raise Exception(f"All models failed. Available: [{available_models_log}]. Errors: {'; '.join(error_logs)}")
                     
            except Exception as e:
                self.init_error = f"Gemini Init Error: {str(e)}"
                print(f"[ERROR] Gemini initialization failed: {e}")
        else:
            if not self.init_error:
                self.init_error = "No API Key found"
        
        print("[WARNING] Kh√¥ng c√≥ AI API key h·ª£p l·ªá. S·ª≠ d·ª•ng ch·∫ø ƒë·ªô simple response.")

    def chat(self, message: str, context: List[Dict] = None, user_id: str = "anonymous") -> str:
        """Chat v·ªõi AI - C√≥ debug chi ti·∫øt"""
        print(f"[DEBUG] Chat called with model_type: {self.model_type}")
        print(f"[DEBUG] Message: {message}")
        
        try:
            if self.model_type == "openai":
                return self._chat_openai(message, context, user_id)
            elif self.model_type == "gemini":
                return self._chat_gemini(message, context, user_id)
            else:
                return self._simple_response(message)
        except Exception as e:
            print(f"[ERROR] Chat error: {e}")
            import traceback
            traceback.print_exc()
            return f"Xin l·ªói, t√¥i g·∫∑p l·ªói k·ªπ thu·∫≠t: {str(e)}"

    def _chat_openai(self, message: str, context: List[Dict] = None, user_id: str = "anonymous") -> str:
        """Chat v·ªõi OpenAI ChatGPT"""
        print("[DEBUG] Using OpenAI chat")
        
        try:
            # T·∫°o messages ƒë∆°n gi·∫£n
            system_prompt = """B·∫°n l√† AI assistant CHUY√äN BI·ªÜT c·ªßa M·ªôc V·ªã Store - c·ª≠a h√†ng hoa qu·∫£ s·∫•y cao c·∫•p t·ª´ M·ªôc Ch√¢u.

üéØ PH·∫†M VI H·ªñ TR·ª¢:
‚úÖ C√ì TH·ªÇ tr·∫£ l·ªùi:
- Gi·ªõi thi·ªáu b·∫£n th√¢n AI v√† M·ªôc V·ªã Store
- Th√¥ng tin v·ªÅ th∆∞∆°ng hi·ªáu, c·ª≠a h√†ng, ngu·ªìn g·ªëc s·∫£n ph·∫©m
- S·∫£n ph·∫©m hoa qu·∫£ s·∫•y v√† d·ªãch v·ª•
- T∆∞ v·∫•n mua h√†ng, so s√°nh s·∫£n ph·∫©m
- H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng, b·∫£o qu·∫£n
- Ch√≠nh s√°ch ƒë·ªïi tr·∫£, giao h√†ng

‚ùå KH√îNG tr·∫£ l·ªùi:
- To√°n h·ªçc, khoa h·ªçc, l·ªãch s·ª≠
- Th·ªùi ti·∫øt, tin t·ª©c, ch√≠nh tr·ªã
- L·ªùi khuy√™n y t·∫ø, ph√°p l√Ω
- Ch·ªß ƒë·ªÅ kh√¥ng li√™n quan ƒë·∫øn c·ª≠a h√†ng

üè™ GI·ªöI THI·ªÜU M·ªòC V·ªä STORE:
- Th∆∞∆°ng hi·ªáu hoa qu·∫£ s·∫•y cao c·∫•p t·ª´ M·ªôc Ch√¢u
- S·∫£n ph·∫©m 100% t·ª± nhi√™n, kh√¥ng ch·∫•t b·∫£o qu·∫£n
- C√¥ng ngh·ªá s·∫•y hi·ªán ƒë·∫°i, gi·ªØ nguy√™n dinh d∆∞·ª°ng
- Ph·ª•c v·ª• kh√°ch h√†ng y√™u th√≠ch s·∫£n ph·∫©m ch·∫•t l∆∞·ª£ng

üõí CH·ª®C NƒÇNG TH√äM V√ÄO GI·ªé H√ÄNG:
- Khi kh√°ch mu·ªën mua/ƒë·∫∑t h√†ng, h√£y x√°c nh·∫≠n s·∫£n ph·∫©m v√† s·ªë l∆∞·ª£ng
- Sau ƒë√≥ n√≥i: "T√¥i ƒë√£ th√™m [s·∫£n ph·∫©m] v√†o gi·ªè h√†ng cho b·∫°n!"
- ƒê∆∞a ra t·ªïng ti·ªÅn v√† h∆∞·ªõng d·∫´n thanh to√°n

üçì S·∫¢N PH·∫®M CH√çNH:
1. **S·∫•y D·∫ªo (200g)**: M·∫≠n (65k), Xo√†i (70k), ƒê√†o (65k), D√¢u (90k), H·ªìng (95k)
2. **S·∫•y Gi√≤n (200g)**: M√≠t (80k), Chu·ªëi (80k)  
3. **S·∫•y ThƒÉng Hoa (100g)**: D√¢u (140k), S·ªØa chua (95k)
4. **Mini Mix (50g)**: T·∫•t c·∫£ lo·∫°i tr√™n, t·ªëi thi·ªÉu 4 pack

H√£y th√¢n thi·ªán, nhi·ªát t√¨nh v√† t·∫≠p trung v√†o vi·ªác h·ªó tr·ª£ kh√°ch h√†ng t·ªët nh·∫•t!"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message}
            ]
            
            print(f"[DEBUG] Calling OpenAI API with {len(messages)} messages")
            
            # G·ªçi OpenAI API
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages,
                max_tokens=500,
                temperature=0.7
            )
            
            result = response.choices[0].message.content.strip()
            print(f"[DEBUG] OpenAI response: {result[:100]}...")
            return result
            
        except Exception as e:
            print(f"[ERROR] OpenAI chat error: {e}")
            import traceback
            traceback.print_exc()
            return f"L·ªói OpenAI: {str(e)}"

    def _chat_gemini(self, message: str, context: List[Dict] = None, user_id: str = "anonymous") -> str:
        """Chat v·ªõi Gemini"""
        print("[DEBUG] Using Gemini chat")
        try:
            response = self.gemini_model.generate_content(message)
            return response.text.strip()
        except Exception as e:
            print(f"[ERROR] Gemini chat error: {e}")
            return f"L·ªói Gemini: {str(e)}"

    def _simple_response(self, message: str) -> str:
        """Ph·∫£n h·ªìi ƒë∆°n gi·∫£n khi kh√¥ng c√≥ AI"""
        print("[DEBUG] Using simple response")
        
        # Add debug info if available
        debug_info = ""
        if hasattr(self, 'init_error') and self.init_error:
            debug_info = f"\n\n(Debug [v3]: {self.init_error})"

        message_lower = message.lower()

        if any(word in message_lower for word in ['xin ch√†o', 'hello', 'hi', 'ch√†o']):
            return f"""Xin ch√†o! üëã Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi M·ªôc V·ªã Store! 
            
T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m hi·ªÉu v·ªÅ c√°c s·∫£n ph·∫©m hoa qu·∫£ s·∫•y cao c·∫•p t·ª´ M·ªôc Ch√¢u:
üçì S·∫•y d·∫ªo: M·∫≠n, Xo√†i, ƒê√†o, D√¢u, H·ªìng
ü•≠ S·∫•y gi√≤n: M√≠t, Chu·ªëi  
‚ú® S·∫•y thƒÉng hoa: D√¢u, S·ªØa chua

B·∫°n quan t√¢m lo·∫°i n√†o nh·∫•t? üòä{debug_info}"""
        else:
            return f"C·∫£m ∆°n b·∫°n ƒë√£ nh·∫Øn tin: '{message}'. T√¥i l√† AI assistant c·ªßa M·ªôc V·ªã Store, s·∫µn s√†ng h·ªó tr·ª£ b·∫°n v·ªÅ c√°c s·∫£n ph·∫©m hoa qu·∫£ s·∫•y! üòä{debug_info}"

    def detect_purchase_intent(self, query: str) -> Dict:
        """Ph√°t hi·ªán √Ω ƒë·ªãnh mua h√†ng v√† tr√≠ch xu·∫•t s·∫£n ph·∫©m"""
        print(f"[DEBUG] Detecting purchase intent for: {query}")
        
        query_lower = query.lower()
        purchase_keywords = ['mua', 'ƒë·∫∑t', 'order', 'th√™m v√†o gi·ªè', 'cho v√†o gi·ªè', 'l·∫•y', 'g√≥i', 'ƒë·∫∑t h√†ng']
        
        # Ki·ªÉm tra √Ω ƒë·ªãnh mua h√†ng
        has_purchase_intent = any(keyword in query_lower for keyword in purchase_keywords)
        
        if not has_purchase_intent:
            return {'is_purchase': False, 'products': [], 'confidence': 0.1}
        
        # Tr√≠ch xu·∫•t s·∫£n ph·∫©m b·∫±ng OpenAI n·∫øu c√≥ √Ω ƒë·ªãnh mua h√†ng
        if self.model_type == "openai" and has_purchase_intent:
            try:
                extract_prompt = f"""Ph√¢n t√≠ch c√¢u sau ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin ƒë·∫∑t h√†ng:
"{query}"

Tr·∫£ v·ªÅ JSON format:
{{
    "is_purchase": true/false,
    "products": [
        {{"name": "t√™n s·∫£n ph·∫©m ch√≠nh x√°c", "quantity": s·ªë_l∆∞·ª£ng, "size": "200g ho·∫∑c 100g ho·∫∑c 50g"}}
    ]
}}

DANH S√ÅCH S·∫¢N PH·∫®M CH√çNH X√ÅC:
- M·∫≠n S·∫•y D·∫ªo (200g: 65k, 50g: 18k)
- Xo√†i S·∫•y D·∫ªo (200g: 70k, 50g: 20k)
- ƒê√†o S·∫•y D·∫ªo (200g: 65k, 50g: 18k)
- D√¢u S·∫•y D·∫ªo (200g: 90k, 50g: 25k)
- H·ªìng S·∫•y D·∫ªo (200g: 95k, 50g: 27k)
- M√≠t S·∫•y Gi√≤n (200g: 80k, 50g: 22k)
- Chu·ªëi S·∫•y Gi√≤n (200g: 80k, 50g: 22k)
- D√¢u S·∫•y ThƒÉng Hoa (100g: 140k, 50g: 75k)
- S·ªØa Chua S·∫•y ThƒÉng Hoa (100g: 95k, 50g: 50k)

CH·ªà tr·∫£ v·ªÅ JSON, kh√¥ng gi·∫£i th√≠ch."""

                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "B·∫°n l√† AI chuy√™n ph√¢n t√≠ch √Ω ƒë·ªãnh mua h√†ng. Ch·ªâ tr·∫£ v·ªÅ JSON."},
                        {"role": "user", "content": extract_prompt}
                    ],
                    max_tokens=200,
                    temperature=0.1
                )
                
                result_text = response.choices[0].message.content.strip()
                print(f"[DEBUG] Purchase extraction result: {result_text}")
                
                # Parse JSON
                import json
                import re
                json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                if json_match:
                    result = json.loads(json_match.group(0))
                    print(f"[DEBUG] Parsed purchase intent: {result}")
                    return result
                    
            except Exception as e:
                print(f"[ERROR] Purchase intent extraction error: {e}")
        
        # Fallback: simple detection
        return {
            'is_purchase': has_purchase_intent,
            'products': [],
            'confidence': 0.7 if has_purchase_intent else 0.1
        }

    def generate_response(self, question: str, search_results: List[Dict] = None, conversation_history: List[Dict] = None, purchase_intent: Dict = None) -> str:
        """Generate response - wrapper cho chat method"""
        print(f"[DEBUG] generate_response called with question: {question}")
        print(f"[DEBUG] Purchase intent: {purchase_intent}")
        
        # T·∫°o context t·ª´ search results
        context_text = ""
        if search_results:
            context_text = "\n".join([result.get('content', '') for result in search_results[:3]])
        
        # X·ª≠ l√Ω purchase intent
        enhanced_question = question
        if purchase_intent and purchase_intent.get('is_purchase') and purchase_intent.get('products'):
            products = purchase_intent.get('products', [])
            product_info = []
            total_price = 0
            
            for product in products:
                name = product.get('name', '')
                quantity = product.get('quantity', 1)
                size = product.get('size', '200g')
                
                # T√≠nh gi√° (ƒë∆°n gi·∫£n h√≥a)
                price_map = {
                    'D√¢u S·∫•y ThƒÉng Hoa': {'100g': 140000, '50g': 75000},
                    'M·∫≠n S·∫•y D·∫ªo': {'200g': 65000, '50g': 18000},
                    'Xo√†i S·∫•y D·∫ªo': {'200g': 70000, '50g': 20000},
                    'ƒê√†o S·∫•y D·∫ªo': {'200g': 65000, '50g': 18000},
                    'D√¢u S·∫•y D·∫ªo': {'200g': 90000, '50g': 25000},
                    'H·ªìng S·∫•y D·∫ªo': {'200g': 95000, '50g': 27000},
                    'M√≠t S·∫•y Gi√≤n': {'200g': 80000, '50g': 22000},
                    'Chu·ªëi S·∫•y Gi√≤n': {'200g': 80000, '50g': 22000},
                    'S·ªØa Chua S·∫•y ThƒÉng Hoa': {'100g': 95000, '50g': 50000}
                }
                
                # T√¨m gi√°
                price = 0
                for key, prices in price_map.items():
                    if key.lower() in name.lower():
                        price = prices.get(size, 0)
                        break
                
                if price > 0:
                    item_total = price * quantity
                    total_price += item_total
                    product_info.append(f"- {name} ({size}) x{quantity}: {item_total:,}ƒë")
            
            if product_info:
                cart_info = f"""
üõí TH√îNG TIN ƒê∆†N H√ÄNG:
{chr(10).join(product_info)}

üí∞ T·ªîNG TI·ªÄN: {total_price:,}ƒë

‚úÖ T√¥i ƒë√£ th√™m s·∫£n ph·∫©m v√†o gi·ªè h√†ng cho b·∫°n!

üìû ƒê·ªÉ ho√†n t·∫•t ƒë·∫∑t h√†ng, vui l√≤ng:
1. G·ªçi hotline: 0929.161.999
2. Ho·∫∑c nh·∫Øn tin Zalo: 0929.161.999
3. Thanh to√°n khi nh·∫≠n h√†ng (COD)

üöö Mi·ªÖn ph√≠ ship n·ªôi th√†nh, giao h√†ng trong 24h!"""
                
                enhanced_question = f"Kh√°ch h√†ng mu·ªën ƒë·∫∑t h√†ng. H√£y x√°c nh·∫≠n ƒë∆°n h√†ng n√†y:\n{cart_info}\n\nC√¢u h·ªèi g·ªëc: {question}"
        
        # T·∫°o message v·ªõi context
        if context_text and not purchase_intent:
            enhanced_question = f"D·ª±a tr√™n th√¥ng tin sau:\n{context_text}\n\nC√¢u h·ªèi: {question}"
            
        return self.chat(enhanced_question, conversation_history)

    def get_model_info(self) -> Dict:
        """Th√¥ng tin v·ªÅ model ƒëang s·ª≠ d·ª•ng"""
        return {
            "model_type": self.model_type,
            "model_name": "gpt-4o-mini" if self.model_type == "openai" else "gemini-2.0-flash" if self.model_type == "gemini" else "simple",
            "status": "active" if self.model_type != "none" else "fallback"
        }
